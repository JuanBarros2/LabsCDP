---
title: ""
author: "Juan Barros"
date: "09 de Novembro de 2018"
output:
  html_document:
      df_print: paged
      toc: yes
      toc_float: yes
  html_notebook:
      toc: yes
      toc_float: yes
---

```{r include=FALSE}
library(caret)
library(tidyverse)
```

```{r importarDados}
dados <- read.csv("train.csv")

validacaoCruzada <- trainControl(method = "cv", number = 5, )

logisticModel <- train(
  situacao~ .,
  data = dados %>% select(-cargo),
  method = "regLogistic",
  trControl = validacaoCruzada)
```
### Questões
Nessa atividade você irá usar seus conhecimentos sobre classificação para prever quais candidatos à Câmara de Deputados serão eleitos nas eleições de 2014. De forma específica faremos o seguinte:

#### Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso?

Inicialmente, analizarei os dados do atributo "situação" para verificar a distribuição dos dados. 
```{r}
summary(dados$situacao)
```
O resultado acima corresponde a quantidade de deputados eleitos (1026) e não eleitos (6596) nesse conjunto de dados. Só com esses valores podemos afirmar que os dados não estão devidamente balanceados para as duas classificações possíveis. A proporção de candidatos eleitos é de aproximadamente 13%, enquanto a de não eleitos é de 83%. O problema disso é que os modelos gerados com esses dados terão um aprendizado tendendo mais para a classe que tiver maior percentual e, nesse caso, acabará eliminando alguns candidados que seriam classificados como "eleito", gerando o que é chamada de erro do tipo 1.
#### Treinamento de modeloslo de regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  (20 pts.)
Para treinar os modelos de regressão logística, árvore de decisão e adaboost, utilizarei o pacote "caret". Utilizarei o mesmo conjunto de dados para os três modelo, tunando apenas os parâmetros que são esperados na entrada do método de treino do caret.

##### Regressão Logística

Para a regressão logística é esperado um parâmetro 
```{r regressaoLogistica}
cctrl1 <- train(method = "cv", number = 3,
                       summaryFunction = twoClassSummary,
                       search = "random", verboseIter = TRUE)
rlGrid <- expand.grid( cost = c(200,2,0.02),
                       epsilon = c(0.001,0.01) )

test_class_cv_form <- train(situacao ~ ., data = dados %>% select(-cargo), 
                            method = "regLogistic", 
                            trControl = cctrl1,
                            preProc = c("center", "scale"))

```

##### Árvore de Decisão
```{r id3}
  
```

##### AdaBoost
```{r adaboost}
  
```

#### Reporte acurácia, precision, recall e f-measure no treino e validação. Há uma grande diferença de desempenho no treino/validação? Como você avalia os resultados? Justifique sua resposta. (10 pt.)

#### Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo? Crie pelo menos um novo atributo que não está nos dados originais e estude o impacto desse atributo (20 pts.)

#### Envie seus melhores modelos à competição do Kaggle. Faça pelo menos uma submissão. Sugestões para melhorar o modelo: (20 pts.)

##### Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting).
##### Experimente balancear as classes,  caso estejam desbalanceadas.
##### Crie pelo menos um novo atributo.